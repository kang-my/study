{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "autograd_tutorial.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRNDrge3maUG"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAPoPWRKmaUL"
      },
      "source": [
        "# 자동미분\n",
        "\n",
        "``autograd`` 패키지 : Tensor의 모든 연산에 대해 자동 미분 제공  \n",
        "실행 - 기반 - 정의(define-by-run) 프레임워크  \n",
        "코드를 어떻게 작성하여 실행하느냐에 따라 역전파가 정의된다는 뜻  \n",
        "\n",
        "\n",
        "##Tensor\n",
        "패키지 중심에는 ``torch.Tensor``클래스 존재  \n",
        "``.requires_grad`` 속성을 ``True``로 설정 : tensor에서 이뤄진 모든 연산을 추적  \n",
        "계산 완료 후 ``backward()``호출 : 모든 변화도(gradient) 자동 계산  \n",
        "이 tensor 변화도 ``.grad``속성에 누적\n",
        "\n",
        "Tensor 기록 추적을 중단하게 하려면 ``.detach()``호출, 연산 기록으로부터 분리  \n",
        "``with tocrch.no_grad():``기록 추적(+메모리 사용)을 방지를 위해 코드 블럭 감싸기  \n",
        "== 변화도는 필요 없지만 requires_grad=True 설정되어 매개변수를 갖는 모델을 평가할 때 유용  \n",
        "\n",
        "\n",
        "### Funchtion 클래스\n",
        "Function과 Tensor는 서로 연결되어 있어 모든 연산과정을 부호화하여 순환하지 않는 그래프(acyclic graph)를 생성  \n",
        "각 tensor는 .grad_fn 속성을 가지는데, 이는 Tensor를 생성한 Function을 참조함\n",
        "(사용자가 만든 Tensor는 예외로 grad_fn은 None)  \n",
        "\n",
        "도함수를 계산하기 위해서는 Tensor 의 .backward() 를 호출  \n",
        "만약 Tensor가 스칼라(하나의 요소 값만 가짐)인 경우 backward에 인자를 정해줄 필요 없음.  \n",
        "여러 개의 요소를 가지고 있는 경우 tensor 모양을 gradient의 인자로 지정해야 함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIS2qyAmmaUM"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ght9oM6maUM"
      },
      "source": [
        "tensor 생성  \n",
        "``set requires_grad=True``설정 == 연산기록\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkbXVI14maUN",
        "outputId": "60c09a46-8736-401d-ffd7-27133e5fc239"
      },
      "source": [
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "print(x)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osXSA2kTmaUN"
      },
      "source": [
        "텐서에 연산 수행\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vjb3lrN_maUN",
        "outputId": "ab54eba3-c4cb-4f72-82d2-c5b9e860d3d3"
      },
      "source": [
        "y = x + 2\n",
        "print(y)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[3., 3.],\n",
            "        [3., 3.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFJcTXtNmaUN"
      },
      "source": [
        "y는 연산의 결과로 생성된 것이므로 ``grad_fn``를 가짐\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0JWknMmmaUO",
        "outputId": "24b0d763-ea85-4443-a1d2-f9992664e491"
      },
      "source": [
        "print(y.grad_fn)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<AddBackward0 object at 0x7f708bc19908>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1l-F3AM6maUO"
      },
      "source": [
        "y에 다른 연산 수행\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xg4VzUqXmaUO",
        "outputId": "0739abf5-44e3-4d7d-9632-57b4bf6d943b"
      },
      "source": [
        "z = y * y * 3\n",
        "out = z.mean()\n",
        "\n",
        "print(z, out)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[27., 27.],\n",
            "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IriRmtDRmaUO"
      },
      "source": [
        "``.requires_grad_( ... )``는 기존 Tensor의 ``requires_grad``를 바꿔치기(in-place) 하여 변경  \n",
        "입력 값이 지정되지 않으면 기본값은 False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "II50yixNmaUP",
        "outputId": "535a34bf-e82c-4064-fb79-53dd215f8cbe"
      },
      "source": [
        "a = torch.randn(2, 2) # torch 생성\n",
        "print(a)\n",
        "a = ((a * 3) / (a - 1)) # 값 넣어줌\n",
        "print(a.requires_grad) # 입력값이 지정되지 않으므로 False화\n",
        "a.requires_grad_(True) # 바꿔치기 해서 넣음\n",
        "print(a.requires_grad) # True로 출력됨\n",
        "b = (a * a).sum()\n",
        "print(b.grad_fn)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.9028, -1.1968],\n",
            "        [-0.9403, -0.9543]])\n",
            "False\n",
            "True\n",
            "<SumBackward0 object at 0x7f708bc19c18>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDVICqV8maUP"
      },
      "source": [
        "## 변화도 Gradients\n",
        "\n",
        "역전파 할 예정  \n",
        "out은 스칼라 값만 가지고 있어서  \n",
        "``out.backward()``은 ``out.backward(torch.tensor(1))``와 동일\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkpQmwbRmaUP"
      },
      "source": [
        "out.backward()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B00Yk4AEmaUP"
      },
      "source": [
        "변화도 d(out)/dx 출력\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5rQgVSmmaUP",
        "outputId": "da4da68d-6ac5-4151-c13d-9c26fba5bd05"
      },
      "source": [
        "print(x.grad)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5Vk6-r4maUQ"
      },
      "source": [
        "4.5값으로 이뤄진 행렬 확인  \n",
        "Tensor를 o라고 할때  \n",
        "$o = \\frac{1}{4}\\sum_i z_i$  \n",
        "$z_i = 3(x_i+2)^2$  \n",
        "따라서 $z_i\\bigr\\rvert_{x_i=1} = 27$.\n",
        "\n",
        "$\\frac{\\partial o}{\\partial x_i} = \\frac{3}{2}(x_i+2)$  \n",
        "$\\frac{\\partial o}{\\partial x_i}\\bigr\\rvert_{x_i=1} = \\frac{9}{2} = 4.5$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEt1K1eemaUQ"
      },
      "source": [
        "야코비안 행렬(Jacobian Matrix): 벡터 함수 y⃗ =f(x⃗ ) 에서 x⃗  에 대한 y⃗ 의 변화도  \n",
        "벡터-야코비안 곱의 이러한 특성은 스칼라가 아닌 출력을 갖는 모델에 외부 변화도를 제공(feed)하는 것을 매우 편리하게 해줌  \n",
        "\n",
        "벡터-야코비안 곱의 예제"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsdPWEIZmaUQ",
        "outputId": "9318f9bc-d070-45a5-a741-8947400abe2b"
      },
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "\n",
        "y = x * 2\n",
        "while y.data.norm() < 1000:\n",
        "    y = y * 2\n",
        "\n",
        "print(y)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 759.5015,  240.4281, -771.1067], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRrMh2uKyGh4"
      },
      "source": [
        "이제 y는 더이상 스칼라 값이 아님.  \r\n",
        "torch.autograd는 전체 야코비안을 직접계산할 수 없지만  \r\n",
        "벡터-야코비안 곲은 간단히 backward에 해당 벡터를 인자로 제공하여 얻을 수 있음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcM-z0UmmaUQ",
        "outputId": "8fe10e42-7d99-4806-daea-7caa7dfac353"
      },
      "source": [
        "gradients = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
        "y.backward(gradients)\n",
        "\n",
        "print(x.grad)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJQL6noKmaUQ"
      },
      "source": [
        "``with torch.no_grad():``으로 코드를 감싸 autograd가 ``.requires_grad=True``인 Tensor 연산 기록 추적을 멈출 수 있게 함\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M22nKh_lmaUR",
        "outputId": "edffcb0e-2d86-4d29-d89e-910bbf5d7221"
      },
      "source": [
        "print(x.requires_grad)\n",
        "print((x ** 2).requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "\tprint((x ** 2).requires_grad)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}